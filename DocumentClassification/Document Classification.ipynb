{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9c46774",
   "metadata": {},
   "source": [
    "## Assignment 5-6: Document Classification\n",
    "#### Summer 2021\n",
    "**Authors:** GOAT Team (Estaban Aramayo, Ethan Haley, Claire Meyer, and Tyler Frankenburg)\n",
    "\n",
    "In this assignment, we'll ingest a dataset on spam emails from the [UCI Machine Learning Repository](http://archive.ics.uci.edu/ml/datasets/Spambase) and build a classifier to predict if a row is a spam email or not, using the included features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "6ed0f11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5f24f4",
   "metadata": {},
   "source": [
    "##### Configuring the Spam dataset\n",
    "\n",
    "First we'll import the email data into a CSV without headers, as we'll add the column names from the names file later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9ff56091",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_data = pd.read_csv(\"https://raw.githubusercontent.com/ebhtra/gory-graph/main/DocumentClassification/spambase.data\",header=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "299eb511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0.64</th>\n",
       "      <th>0.64.1</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.32</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>...</th>\n",
       "      <th>0.40</th>\n",
       "      <th>0.41</th>\n",
       "      <th>0.42</th>\n",
       "      <th>0.778</th>\n",
       "      <th>0.43</th>\n",
       "      <th>0.44</th>\n",
       "      <th>3.756</th>\n",
       "      <th>61</th>\n",
       "      <th>278</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>15</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0  0.64  0.64.1  0.1  0.32   0.2   0.3   0.4   0.5   0.6  ...  0.40  \\\n",
       "0  0.21  0.28    0.50  0.0  0.14  0.28  0.21  0.07  0.00  0.94  ...  0.00   \n",
       "1  0.06  0.00    0.71  0.0  1.23  0.19  0.19  0.12  0.64  0.25  ...  0.01   \n",
       "2  0.00  0.00    0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.00   \n",
       "3  0.00  0.00    0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.00   \n",
       "4  0.00  0.00    0.00  0.0  1.85  0.00  0.00  1.85  0.00  0.00  ...  0.00   \n",
       "\n",
       "    0.41  0.42  0.778   0.43   0.44  3.756   61   278  1  \n",
       "0  0.132   0.0  0.372  0.180  0.048  5.114  101  1028  1  \n",
       "1  0.143   0.0  0.276  0.184  0.010  9.821  485  2259  1  \n",
       "2  0.137   0.0  0.137  0.000  0.000  3.537   40   191  1  \n",
       "3  0.135   0.0  0.135  0.000  0.000  3.537   40   191  1  \n",
       "4  0.223   0.0  0.000  0.000  0.000  3.000   15    54  1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734367f0",
   "metadata": {},
   "source": [
    "Then we open the names file, which includes names for all our eventual features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a3c07095",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"/Users/clairemeyer/Downloads/spambase/spambase.names\", \"r\")\n",
    "#f = open(\"https://raw.githubusercontent.com/ebhtra/gory-graph/main/DocumentClassification/spambase.names\", \"r\")\n",
    "f = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c426ac7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| SPAM E-MAIL DATABASE ATTRIBUTES (in .names format)\n",
      "|\n",
      "| 48 continuous real [0,100] attributes of type word_freq_WORD \n",
      "| = percentage of words in the e-mail that match WORD,\n",
      "| i.e. 100 * (number of times the WORD appears in the e-mail) / \n",
      "| total number of words in e-mail.  A \"word\" in this case is any \n",
      "| string of alphanumeric characters bounded by non-alphanumeric \n",
      "| characters or end-of-string.\n",
      "|\n",
      "| 6 continuous real [0,100] attributes of type char_freq_CHAR\n",
      "| = percentage of characters in the e-mail that match CHAR,\n",
      "| i.e. 100 * (number of CHAR occurences) / total characters in e-mail\n",
      "|\n",
      "| 1 continuous real [1,...] attribute of type capital_run_length_average\n",
      "| = average length of uninterrupted sequences of capital letters\n",
      "|\n",
      "| 1 continuous integer [1,...] attribute of type capital_run_length_longest\n",
      "| = length of longest uninterrupted sequence of capital letters\n",
      "|\n",
      "| 1 continuous integer [1,...] attribute of type capital_run_length_total\n",
      "| = sum of length of uninterrupted sequences of capital letters\n",
      "| = total number of capital letters in the e-mail\n",
      "|\n",
      "| 1 nominal {0,1} class attribute of type spam\n",
      "| = denotes whether the e-mail was considered spam (1) or not (0), \n",
      "| i.e. unsolicited commercial e-mail.  \n",
      "|\n",
      "| For more information, see file 'spambase.DOCUMENTATION' at the\n",
      "| UCI Machine Learning Repository: http://www.ics.uci.edu/~mlearn/MLRepository.html\n",
      "\n",
      "\n",
      "1, 0.    | spam, non-spam classes\n",
      "\n",
      "word_freq_make:         continuous.\n",
      "word_freq_address:      continuous.\n",
      "word_freq_all:          continuous.\n",
      "word_freq_3d:           continuous.\n",
      "word_freq_our:          continuous.\n",
      "word_freq_over:         continuous.\n",
      "word_freq_remove:       continuous.\n",
      "word_freq_internet:     continuous.\n",
      "word_freq_order:        continuous.\n",
      "word_freq_mail:         continuous.\n",
      "word_freq_receive:      continuous.\n",
      "word_freq_will:         continuous.\n",
      "word_freq_people:       continuous.\n",
      "word_freq_report:       continuous.\n",
      "word_freq_addresses:    continuous.\n",
      "word_freq_free:         continuous.\n",
      "word_freq_business:     continuous.\n",
      "word_freq_email:        continuous.\n",
      "word_freq_you:          continuous.\n",
      "word_freq_credit:       continuous.\n",
      "word_freq_your:         continuous.\n",
      "word_freq_font:         continuous.\n",
      "word_freq_000:          continuous.\n",
      "word_freq_money:        continuous.\n",
      "word_freq_hp:           continuous.\n",
      "word_freq_hpl:          continuous.\n",
      "word_freq_george:       continuous.\n",
      "word_freq_650:          continuous.\n",
      "word_freq_lab:          continuous.\n",
      "word_freq_labs:         continuous.\n",
      "word_freq_telnet:       continuous.\n",
      "word_freq_857:          continuous.\n",
      "word_freq_data:         continuous.\n",
      "word_freq_415:          continuous.\n",
      "word_freq_85:           continuous.\n",
      "word_freq_technology:   continuous.\n",
      "word_freq_1999:         continuous.\n",
      "word_freq_parts:        continuous.\n",
      "word_freq_pm:           continuous.\n",
      "word_freq_direct:       continuous.\n",
      "word_freq_cs:           continuous.\n",
      "word_freq_meeting:      continuous.\n",
      "word_freq_original:     continuous.\n",
      "word_freq_project:      continuous.\n",
      "word_freq_re:           continuous.\n",
      "word_freq_edu:          continuous.\n",
      "word_freq_table:        continuous.\n",
      "word_freq_conference:   continuous.\n",
      "char_freq_;:            continuous.\n",
      "char_freq_(:            continuous.\n",
      "char_freq_[:            continuous.\n",
      "char_freq_!:            continuous.\n",
      "char_freq_$:            continuous.\n",
      "char_freq_#:            continuous.\n",
      "capital_run_length_average: continuous.\n",
      "capital_run_length_longest: continuous.\n",
      "capital_run_length_total:   continuous.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a542a7b0",
   "metadata": {},
   "source": [
    "Using Regex findall(), we can use pattern matching to ignore documentation text and pull in all the feature names to use as columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5c6e342c",
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = re.findall(\"word_freq_[a-z]*:|word_freq_[a-z]*[0-9]*[a-z]:|word_freq_[a-z]*[0-9]*:|char_freq_.:|capital_run_length_[a-z]*:\",f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "186150ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames\n",
    "colnames.append(\"spam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5d3e62cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\n"
     ]
    }
   ],
   "source": [
    "print(len(colnames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d62698a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_data.columns = colnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d8dda86d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make:</th>\n",
       "      <th>word_freq_address:</th>\n",
       "      <th>word_freq_all:</th>\n",
       "      <th>word_freq_3d:</th>\n",
       "      <th>word_freq_our:</th>\n",
       "      <th>word_freq_over:</th>\n",
       "      <th>word_freq_remove:</th>\n",
       "      <th>word_freq_internet:</th>\n",
       "      <th>word_freq_order:</th>\n",
       "      <th>word_freq_mail:</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_;:</th>\n",
       "      <th>char_freq_(:</th>\n",
       "      <th>char_freq_[:</th>\n",
       "      <th>char_freq_!:</th>\n",
       "      <th>char_freq_$:</th>\n",
       "      <th>char_freq_#:</th>\n",
       "      <th>capital_run_length_average:</th>\n",
       "      <th>capital_run_length_longest:</th>\n",
       "      <th>capital_run_length_total:</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>15</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_freq_make:  word_freq_address:  word_freq_all:  word_freq_3d:  \\\n",
       "0             0.21                0.28            0.50            0.0   \n",
       "1             0.06                0.00            0.71            0.0   \n",
       "2             0.00                0.00            0.00            0.0   \n",
       "3             0.00                0.00            0.00            0.0   \n",
       "4             0.00                0.00            0.00            0.0   \n",
       "\n",
       "   word_freq_our:  word_freq_over:  word_freq_remove:  word_freq_internet:  \\\n",
       "0            0.14             0.28               0.21                 0.07   \n",
       "1            1.23             0.19               0.19                 0.12   \n",
       "2            0.63             0.00               0.31                 0.63   \n",
       "3            0.63             0.00               0.31                 0.63   \n",
       "4            1.85             0.00               0.00                 1.85   \n",
       "\n",
       "   word_freq_order:  word_freq_mail:  ...  char_freq_;:  char_freq_(:  \\\n",
       "0              0.00             0.94  ...          0.00         0.132   \n",
       "1              0.64             0.25  ...          0.01         0.143   \n",
       "2              0.31             0.63  ...          0.00         0.137   \n",
       "3              0.31             0.63  ...          0.00         0.135   \n",
       "4              0.00             0.00  ...          0.00         0.223   \n",
       "\n",
       "   char_freq_[:  char_freq_!:  char_freq_$:  char_freq_#:  \\\n",
       "0           0.0         0.372         0.180         0.048   \n",
       "1           0.0         0.276         0.184         0.010   \n",
       "2           0.0         0.137         0.000         0.000   \n",
       "3           0.0         0.135         0.000         0.000   \n",
       "4           0.0         0.000         0.000         0.000   \n",
       "\n",
       "   capital_run_length_average:  capital_run_length_longest:  \\\n",
       "0                        5.114                          101   \n",
       "1                        9.821                          485   \n",
       "2                        3.537                           40   \n",
       "3                        3.537                           40   \n",
       "4                        3.000                           15   \n",
       "\n",
       "   capital_run_length_total:  spam  \n",
       "0                       1028     1  \n",
       "1                       2259     1  \n",
       "2                        191     1  \n",
       "3                        191     1  \n",
       "4                         54     1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff529d0",
   "metadata": {},
   "source": [
    "##### Exploring the Data\n",
    "\n",
    "Let's look at class balance, as well as descriptive statistics of each field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d1f0f6d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make:</th>\n",
       "      <th>word_freq_address:</th>\n",
       "      <th>word_freq_all:</th>\n",
       "      <th>word_freq_3d:</th>\n",
       "      <th>word_freq_our:</th>\n",
       "      <th>word_freq_over:</th>\n",
       "      <th>word_freq_remove:</th>\n",
       "      <th>word_freq_internet:</th>\n",
       "      <th>word_freq_order:</th>\n",
       "      <th>word_freq_mail:</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_;:</th>\n",
       "      <th>char_freq_(:</th>\n",
       "      <th>char_freq_[:</th>\n",
       "      <th>char_freq_!:</th>\n",
       "      <th>char_freq_$:</th>\n",
       "      <th>char_freq_#:</th>\n",
       "      <th>capital_run_length_average:</th>\n",
       "      <th>capital_run_length_longest:</th>\n",
       "      <th>capital_run_length_total:</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.104576</td>\n",
       "      <td>0.212922</td>\n",
       "      <td>0.280578</td>\n",
       "      <td>0.065439</td>\n",
       "      <td>0.312222</td>\n",
       "      <td>0.095922</td>\n",
       "      <td>0.114233</td>\n",
       "      <td>0.105317</td>\n",
       "      <td>0.090087</td>\n",
       "      <td>0.239465</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038583</td>\n",
       "      <td>0.139061</td>\n",
       "      <td>0.016980</td>\n",
       "      <td>0.268960</td>\n",
       "      <td>0.075827</td>\n",
       "      <td>0.044248</td>\n",
       "      <td>5.191827</td>\n",
       "      <td>52.170870</td>\n",
       "      <td>283.290435</td>\n",
       "      <td>0.393913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.305387</td>\n",
       "      <td>1.290700</td>\n",
       "      <td>0.504170</td>\n",
       "      <td>1.395303</td>\n",
       "      <td>0.672586</td>\n",
       "      <td>0.273850</td>\n",
       "      <td>0.391480</td>\n",
       "      <td>0.401112</td>\n",
       "      <td>0.278643</td>\n",
       "      <td>0.644816</td>\n",
       "      <td>...</td>\n",
       "      <td>0.243497</td>\n",
       "      <td>0.270377</td>\n",
       "      <td>0.109406</td>\n",
       "      <td>0.815726</td>\n",
       "      <td>0.245906</td>\n",
       "      <td>0.429388</td>\n",
       "      <td>31.732891</td>\n",
       "      <td>194.912453</td>\n",
       "      <td>606.413764</td>\n",
       "      <td>0.488669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.588000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.275500</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.382500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.188000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.314250</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.705250</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>265.250000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.540000</td>\n",
       "      <td>14.280000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>42.810000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.880000</td>\n",
       "      <td>7.270000</td>\n",
       "      <td>11.110000</td>\n",
       "      <td>5.260000</td>\n",
       "      <td>18.180000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.385000</td>\n",
       "      <td>9.752000</td>\n",
       "      <td>4.081000</td>\n",
       "      <td>32.478000</td>\n",
       "      <td>6.003000</td>\n",
       "      <td>19.829000</td>\n",
       "      <td>1102.500000</td>\n",
       "      <td>9989.000000</td>\n",
       "      <td>15841.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       word_freq_make:  word_freq_address:  word_freq_all:  word_freq_3d:  \\\n",
       "count      4600.000000         4600.000000     4600.000000    4600.000000   \n",
       "mean          0.104576            0.212922        0.280578       0.065439   \n",
       "std           0.305387            1.290700        0.504170       1.395303   \n",
       "min           0.000000            0.000000        0.000000       0.000000   \n",
       "25%           0.000000            0.000000        0.000000       0.000000   \n",
       "50%           0.000000            0.000000        0.000000       0.000000   \n",
       "75%           0.000000            0.000000        0.420000       0.000000   \n",
       "max           4.540000           14.280000        5.100000      42.810000   \n",
       "\n",
       "       word_freq_our:  word_freq_over:  word_freq_remove:  \\\n",
       "count     4600.000000      4600.000000        4600.000000   \n",
       "mean         0.312222         0.095922           0.114233   \n",
       "std          0.672586         0.273850           0.391480   \n",
       "min          0.000000         0.000000           0.000000   \n",
       "25%          0.000000         0.000000           0.000000   \n",
       "50%          0.000000         0.000000           0.000000   \n",
       "75%          0.382500         0.000000           0.000000   \n",
       "max         10.000000         5.880000           7.270000   \n",
       "\n",
       "       word_freq_internet:  word_freq_order:  word_freq_mail:  ...  \\\n",
       "count          4600.000000       4600.000000      4600.000000  ...   \n",
       "mean              0.105317          0.090087         0.239465  ...   \n",
       "std               0.401112          0.278643         0.644816  ...   \n",
       "min               0.000000          0.000000         0.000000  ...   \n",
       "25%               0.000000          0.000000         0.000000  ...   \n",
       "50%               0.000000          0.000000         0.000000  ...   \n",
       "75%               0.000000          0.000000         0.160000  ...   \n",
       "max              11.110000          5.260000        18.180000  ...   \n",
       "\n",
       "       char_freq_;:  char_freq_(:  char_freq_[:  char_freq_!:  char_freq_$:  \\\n",
       "count   4600.000000   4600.000000   4600.000000   4600.000000   4600.000000   \n",
       "mean       0.038583      0.139061      0.016980      0.268960      0.075827   \n",
       "std        0.243497      0.270377      0.109406      0.815726      0.245906   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.065000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.188000      0.000000      0.314250      0.052000   \n",
       "max        4.385000      9.752000      4.081000     32.478000      6.003000   \n",
       "\n",
       "       char_freq_#:  capital_run_length_average:  capital_run_length_longest:  \\\n",
       "count   4600.000000                  4600.000000                  4600.000000   \n",
       "mean       0.044248                     5.191827                    52.170870   \n",
       "std        0.429388                    31.732891                   194.912453   \n",
       "min        0.000000                     1.000000                     1.000000   \n",
       "25%        0.000000                     1.588000                     6.000000   \n",
       "50%        0.000000                     2.275500                    15.000000   \n",
       "75%        0.000000                     3.705250                    43.000000   \n",
       "max       19.829000                  1102.500000                  9989.000000   \n",
       "\n",
       "       capital_run_length_total:         spam  \n",
       "count                4600.000000  4600.000000  \n",
       "mean                  283.290435     0.393913  \n",
       "std                   606.413764     0.488669  \n",
       "min                     1.000000     0.000000  \n",
       "25%                    35.000000     0.000000  \n",
       "50%                    95.000000     0.000000  \n",
       "75%                   265.250000     1.000000  \n",
       "max                 15841.000000     1.000000  \n",
       "\n",
       "[8 rows x 58 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c6f5bf16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2788\n",
       "1    1812\n",
       "Name: spam, dtype: int64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_data['spam'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154caa6f",
   "metadata": {},
   "source": [
    "This dataset contains just under 40% spam, so the classes are not perfectly balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbe19af",
   "metadata": {},
   "source": [
    "##### Building the classifier\n",
    "\n",
    "We're going to play with sci-kit learn classification models. To start, we'll split our target, y, from our features, X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "083b17ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = spam_data.iloc[:,57]\n",
    "X = spam_data.iloc[:,:57]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "59de75c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   word_freq_make:  word_freq_address:  word_freq_all:  word_freq_3d:  \\\n",
      "0             0.21                0.28            0.50            0.0   \n",
      "1             0.06                0.00            0.71            0.0   \n",
      "2             0.00                0.00            0.00            0.0   \n",
      "3             0.00                0.00            0.00            0.0   \n",
      "4             0.00                0.00            0.00            0.0   \n",
      "\n",
      "   word_freq_our:  word_freq_over:  word_freq_remove:  word_freq_internet:  \\\n",
      "0            0.14             0.28               0.21                 0.07   \n",
      "1            1.23             0.19               0.19                 0.12   \n",
      "2            0.63             0.00               0.31                 0.63   \n",
      "3            0.63             0.00               0.31                 0.63   \n",
      "4            1.85             0.00               0.00                 1.85   \n",
      "\n",
      "   word_freq_order:  word_freq_mail:  ...  word_freq_conference:  \\\n",
      "0              0.00             0.94  ...                    0.0   \n",
      "1              0.64             0.25  ...                    0.0   \n",
      "2              0.31             0.63  ...                    0.0   \n",
      "3              0.31             0.63  ...                    0.0   \n",
      "4              0.00             0.00  ...                    0.0   \n",
      "\n",
      "   char_freq_;:  char_freq_(:  char_freq_[:  char_freq_!:  char_freq_$:  \\\n",
      "0          0.00         0.132           0.0         0.372         0.180   \n",
      "1          0.01         0.143           0.0         0.276         0.184   \n",
      "2          0.00         0.137           0.0         0.137         0.000   \n",
      "3          0.00         0.135           0.0         0.135         0.000   \n",
      "4          0.00         0.223           0.0         0.000         0.000   \n",
      "\n",
      "   char_freq_#:  capital_run_length_average:  capital_run_length_longest:  \\\n",
      "0         0.048                        5.114                          101   \n",
      "1         0.010                        9.821                          485   \n",
      "2         0.000                        3.537                           40   \n",
      "3         0.000                        3.537                           40   \n",
      "4         0.000                        3.000                           15   \n",
      "\n",
      "   capital_run_length_total:  \n",
      "0                       1028  \n",
      "1                       2259  \n",
      "2                        191  \n",
      "3                        191  \n",
      "4                         54  \n",
      "\n",
      "[5 rows x 57 columns]\n",
      "0    1\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "Name: spam, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X.head())\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df092ddc",
   "metadata": {},
   "source": [
    "Now we'll split into test and train sets using sklearn's built-in splitting function. We'll choose a 30% holdout for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "83c37729",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, test_size=.3, random_state=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288e9a34",
   "metadata": {},
   "source": [
    "Then we can build our classifiers. We'll build a Linear Regression, a Decision Tree, a Random Forest, and a Naive Bayes and compare accuracies across each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "46d14499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9152173913043479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/clairemeyer/opt/anaconda3/envs/sps620env/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "linear_reg = LogisticRegression().fit(X_train, y_train)\n",
    "lin_pred = linear_reg.predict(X_test)\n",
    "lin_score = accuracy_score(y_test, lin_pred)\n",
    "print(lin_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "a3eac8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9036231884057971\n"
     ]
    }
   ],
   "source": [
    "d_tree = DecisionTreeClassifier(max_depth=5).fit(X_train, y_train)\n",
    "dt_pred = d_tree.predict(X_test)\n",
    "dt_score = accuracy_score(y_test, dt_pred)\n",
    "print(dt_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "de632a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9297101449275362\n"
     ]
    }
   ],
   "source": [
    "randomf = RandomForestClassifier(max_depth=5, n_estimators=100).fit(X_train, y_train)\n",
    "rf_pred = randomf.predict(X_test)\n",
    "rf_score = accuracy_score(y_test, rf_pred)\n",
    "print(rf_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "84495ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8231884057971014\n"
     ]
    }
   ],
   "source": [
    "nb = GaussianNB().fit(X_train, y_train)\n",
    "nb_pred = nb.predict(X_test)\n",
    "nb_score = accuracy_score(y_test, nb_pred)\n",
    "print(nb_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bbcbdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a44b4b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e54a944",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
