{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dbd84ed",
   "metadata": {},
   "source": [
    "## Project 3\n",
    "\n",
    "#### Summer 2021\n",
    "**Authors:** GOAT Team (Esteban Aramayo, Ethan Haley, Claire Meyer, and Tyler Frankenburg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60ebe7b",
   "metadata": {},
   "source": [
    "### For Project 3, we'll try to predict genders of unseen names, based on genders of seen names.  \n",
    "\n",
    "**We'll start with nltk's names corpus**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60931336",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f8bedb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = nltk.corpus.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e6d9c833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2943 male names and 5001 female names.\n"
     ]
    }
   ],
   "source": [
    "# are genders balanced?\n",
    "print(f\"{len(names.words('male.txt'))} male names and {len(names.words('female.txt'))} female names.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6875364",
   "metadata": {},
   "source": [
    "So a majority classifier baseline accuracy is 63%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cbf7e986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Ahmet', 'M')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put all names in one list, with gender labels\n",
    "names = [(n, 'M') for n in names.words('male.txt')] + \\\n",
    "        [(n, 'F') for n in names.words('female.txt')]\n",
    "\n",
    "# Shuffle names for ML, setting random seed so we get same results every time\n",
    "random.seed(620)\n",
    "random.shuffle(names)\n",
    "names[2345]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3db5ab96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Em', 'F')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shortest name\n",
    "min(names, key=lambda n: len(n[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "47a88404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Helen-Elizabeth', 'F')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# longest name\n",
    "max(names, key=lambda n: len(n[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e573498c",
   "metadata": {},
   "source": [
    "We can replace those hyphens with spaces, make names lowercase, and add spaces at the start and end of each name too, to signify start and end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8afe74ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(' helen elizabeth ', 'F')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = [(' ' + n[0].lower().replace('-', ' ') + ' ', n[1]) for n in names]\n",
    "\n",
    "max(names, key=lambda n: len(n[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51acd2ee",
   "metadata": {},
   "source": [
    "**Split names into train, dev, and test sets as specified.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c49cd87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests, devs, trains = names[:500], names[500:1000], names[1000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403127c5",
   "metadata": {},
   "source": [
    "#### As an example of feature engineering, we could break every name down into its letter pairs.  So 27 * 27 possible pairs (with spaces)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "28286e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPairs(name):\n",
    "    '''\n",
    "    Given a lowercase name as input, this returns a dictionary \n",
    "    showing which pairs of letters are in the name.\n",
    "    Spaces are allowed, and only binary values are returned, not counts.\n",
    "    '''\n",
    "    letters = ' abcdefghijklmnopqrstuvwxyz'\n",
    "    pairdict = {p1+p2:False for p1 in letters for p2 in letters}\n",
    "    \n",
    "    for i in range(len(name)-1):\n",
    "        pairdict[name[i:i+2]] = True\n",
    "        \n",
    "    return pairdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cbc1b794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getPairs(' jo jo ')['o ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6e30bc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use that function to make the features\n",
    "trainfeats = [(getPairs(n[0]), n[1]) for n in trains]\n",
    "devfeats = [(getPairs(n[0]), n[1]) for n in devs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1e752a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train Naive Bayes model\n",
    "model = nltk.NaiveBayesClassifier.train(trainfeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ecc901d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.816"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check model accuracy on dev set\n",
    "nltk.classify.accuracy(model, devfeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "57696e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                      a  = True                F : M      =     34.7 : 1.0\n",
      "                      f  = True                M : F      =     28.6 : 1.0\n",
      "                      k  = True                M : F      =     28.1 : 1.0\n",
      "                      rv = True                M : F      =     27.5 : 1.0\n",
      "                      fo = True                M : F      =     22.5 : 1.0\n",
      "                      lt = True                M : F      =     21.9 : 1.0\n",
      "                      hu = True                M : F      =     21.9 : 1.0\n",
      "                      iu = True                M : F      =     18.5 : 1.0\n",
      "                      rw = True                M : F      =     17.4 : 1.0\n",
      "                      v  = True                M : F      =     16.2 : 1.0\n",
      "                      p  = True                M : F      =     15.1 : 1.0\n",
      "                      sp = True                M : F      =     15.1 : 1.0\n",
      "                      rk = True                M : F      =     14.5 : 1.0\n",
      "                      dw = True                M : F      =     11.8 : 1.0\n",
      "                      wa = True                M : F      =     11.0 : 1.0\n",
      "                      um = True                M : F      =     10.6 : 1.0\n",
      "                      dl = True                M : F      =      9.5 : 1.0\n",
      "                      ez = True                M : F      =      9.5 : 1.0\n",
      "                      d  = True                M : F      =      9.5 : 1.0\n",
      "                      lf = True                M : F      =      8.8 : 1.0\n"
     ]
    }
   ],
   "source": [
    "# see what the model learned\n",
    "model.show_most_informative_features(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da02e299",
   "metadata": {},
   "source": [
    "The last letter is more important than the first letter.  Also notice that all these informative features other than the top one are indicators of male names.  This may be partly due to the fact that female names account for 63% of the names here.  We might squeeze a little more accuracy out of the model by balancing the training set, i.e. undersampling female names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9ab108",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
